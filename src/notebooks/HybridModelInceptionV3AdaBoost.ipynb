{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parameters\n",
    "IMAGE_SIZE  = (299, 299)\n",
    "BATCH_SIZE  = 32\n",
    "train_dir = '../../data5/train'\n",
    "test_dir  = '../../data5/test'\n",
    "\n",
    "# Create data generators with VGG16-specific preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input))\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Using the test set as \"validation_data\" (not ideal practice)\n",
    "# but shown here due to the 2-folder constraint:\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class labels:\", class_labels)\n",
    "# Compute Class Weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include_top=False removes InceptionV3's default classifier\n",
    "base_model = InceptionV3(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# Example: Freeze first 249 layers, unfreeze the rest\n",
    "for layer in base_model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Add a Custom Head (Penultimate Layer = Embeddings)\n",
    "# -------------------------------------------------\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)   # shape: (batch_size, 2048)\n",
    "x = Dense(256, activation='relu', name='penultimate_layer')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax', name='final_predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=Adam(1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "train_acc  = history.history['accuracy']\n",
    "val_loss   = history.history['val_loss']\n",
    "val_acc    = history.history['val_accuracy']\n",
    "\n",
    "epochs_range = range(len(train_loss))\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss,   label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc,   label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(train_generator, verbose=0)\n",
    "print(f\"Train Accuracy (Keras model): {val_accuracy:.4f}\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
    "print(f\"Test Accuracy (Keras model): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_pred_probs = model.predict(test_generator)\n",
    "# Convert probabilities to class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# True labels from the test generator\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Build Feature Extractor Model\n",
    "#    (Outputs the 'penultimate_layer' embeddings)\n",
    "# -------------------------------------------------\n",
    "feature_extractor = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer('penultimate_layer').output  # the 256-dim layer\n",
    ")\n",
    "feature_extractor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Helper Function to Extract Features\n",
    "# -------------------------------------------------\n",
    "def extract_features_and_labels(generator, extractor):\n",
    "    \"\"\"\n",
    "    Pass all images in 'generator' through 'extractor'\n",
    "    to obtain feature vectors. Also return integer labels.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list   = []\n",
    "    \n",
    "    # Reset generator\n",
    "    generator.reset()\n",
    "    batches = int(np.ceil(generator.samples / generator.batch_size))\n",
    "    \n",
    "    for _ in range(batches):\n",
    "        X_batch, y_batch = next(generator)\n",
    "        batch_features = extractor.predict(X_batch)  # (batch_size, 256)\n",
    "        features_list.append(batch_features)\n",
    "        labels_list.append(y_batch)\n",
    "    \n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels_onehot = np.concatenate(labels_list, axis=0)\n",
    "    labels_int = np.argmax(labels_onehot, axis=1)\n",
    "    return features, labels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Extract Features for Train, Val, and Test\n",
    "# -------------------------------------------------\n",
    "X_train, y_train = extract_features_and_labels(train_generator, feature_extractor)\n",
    "X_test,  y_test  = extract_features_and_labels(test_generator,  feature_extractor)\n",
    "\n",
    "print(\"Train features shape:\", X_train.shape)  # (num_train_samples, 256)\n",
    "print(\"Test  features shape:\", X_test.shape)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12. Train AdaBoost on the Extracted Features\n",
    "# -------------------------------------------------\n",
    "# Example: Using DecisionTree with max_depth=1 as base estimator (common for AdaBoost)\n",
    "ada_params = {\n",
    "    'base_estimator': DecisionTreeClassifier(max_depth=1),\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.5,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(**ada_params)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set (optional)\n",
    "y_test_pred = ada_clf.predict(X_test)\n",
    "val_acc_ada = accuracy_score(y_test, y_test_pred)\n",
    "print(\"AdaBoost Validation Accuracy:\", val_acc_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Final Evaluation on Test Set\n",
    "# -------------------------------------------------\n",
    "y_test_pred = ada_clf.predict(X_test)\n",
    "test_acc_ada = accuracy_score(y_test, y_test_pred)\n",
    "print(\"AdaBoost Test Accuracy:\", test_acc_ada)\n",
    "\n",
    "print(\"\\nClassification Report (AdaBoost):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=class_labels))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix (AdaBoost):\\n\", cm)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Confusion Matrix (AdaBoost)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"../../models/hybrid_model_inception_adaboost.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
